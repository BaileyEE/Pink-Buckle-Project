{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#Asses data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#</td>\n",
       "      <td>Horse\\rAge, Color, Sex\\rSire\\rDam, Dam's Sire</td>\n",
       "      <td>Owner / Rider</td>\n",
       "      <td>Breeder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1st Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>VF Cream Rises\\r2016 Sorrel Mare\\rEddie Stinso...</td>\n",
       "      <td>Ademir Jose Rorato\\r\\rLexington, OK\\r\\rKelsey ...</td>\n",
       "      <td>Victory Farms\\r\\rA\\rda, OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>186</td>\n",
       "      <td>KN Snap Back\\r2016 Mare\\rEddie Stinson\\rKN Han...</td>\n",
       "      <td>Julien Veileux\\r\\rSt. Alfred, Quebec\\r\\rCaroli...</td>\n",
       "      <td>Stephen Nicholes\\r\\rBrownwood, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>163</td>\n",
       "      <td>The Right Version\\r2015 Gray Mare\\rWinners Ver...</td>\n",
       "      <td>Joe Hadley\\r\\rPlain City, UT\\r\\rMcKinlee Kellett</td>\n",
       "      <td>Joe Hadley\\r\\rP  l a  i n City, UT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>Makana\\r2015 Sorrel Mare\\rSlick By Design\\rRod...</td>\n",
       "      <td>Michele McLeod\\r\\rOntario, OR\\r\\rLindsey McLeod</td>\n",
       "      <td>C  h   a  r l i e    C  o  l e    &amp;    J a  s ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                                                  1  \\\n",
       "0    #      Horse\\rAge, Color, Sex\\rSire\\rDam, Dam's Sire   \n",
       "1   13  VF Cream Rises\\r2016 Sorrel Mare\\rEddie Stinso...   \n",
       "2  186  KN Snap Back\\r2016 Mare\\rEddie Stinson\\rKN Han...   \n",
       "3  163  The Right Version\\r2015 Gray Mare\\rWinners Ver...   \n",
       "4   18  Makana\\r2015 Sorrel Mare\\rSlick By Design\\rRod...   \n",
       "\n",
       "                                                   2  \\\n",
       "0                                      Owner / Rider   \n",
       "1  Ademir Jose Rorato\\r\\rLexington, OK\\r\\rKelsey ...   \n",
       "2  Julien Veileux\\r\\rSt. Alfred, Quebec\\r\\rCaroli...   \n",
       "3   Joe Hadley\\r\\rPlain City, UT\\r\\rMcKinlee Kellett   \n",
       "4    Michele McLeod\\r\\rOntario, OR\\r\\rLindsey McLeod   \n",
       "\n",
       "                                                   3    4    5    6    7  \\\n",
       "0                                            Breeder  NaN  NaN  NaN  NaN   \n",
       "1                         Victory Farms\\r\\rA\\rda, OK  NaN  NaN    O  NaN   \n",
       "2                  Stephen Nicholes\\r\\rBrownwood, TX  NaN  NaN    O  NaN   \n",
       "3                 Joe Hadley\\r\\rP  l a  i n City, UT  NaN  NaN    O  NaN   \n",
       "4  C  h   a  r l i e    C  o  l e    &    J a  s ...  NaN  NaN    O  NaN   \n",
       "\n",
       "        8  \n",
       "0  1st Go  \n",
       "1  17.067  \n",
       "2  17.070  \n",
       "3  17.102  \n",
       "4  17.125  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Asses raw data files and apply function above to begin cleaning the data\n",
    "#Year and Go-round could be inputs or pulled from the file string to be \n",
    "df = pd.read_csv(\"PB-Futurity-2020-1st-Go.csv\",  header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function to create tidy data by ensuring each type of \"observation\" has its own column, for each year since result formatting varied.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandcolumns_goround(file):\n",
    "    '''\n",
    "    INPUT string of path to CSV file converted from PDF of go round results from Pink Buckle Futurity\n",
    "    Futurity result formatting varies slightly year to year. \n",
    "    OUTPUT dataframe containing information relative to a stallion's offspring performance\n",
    "    '''\n",
    "    df = pd.read_csv(file,  header = None)\n",
    "    f = file\n",
    "    fvals = f.split(sep = '.')\n",
    "    fvals = fvals[0]\n",
    "    fvals=fvals.split(sep = '-')\n",
    "    sex_list = ['Gelding','Mare','Stallion','M','G','S']\n",
    "    sex_dict = {'G)':'Gelding','M)':'Mare','S)':'Stallion', ' M)':'Mare', 'G':'Gelding'}\n",
    "    if fvals[2] == '2020':\n",
    "    #break column 2 into its own data frame, then create tidy data by ensuring each type of \"observation\" has its own column\n",
    "        col2 = df.iloc[:,1]\n",
    "        col2 = col2.str.split (pat = '\\r',expand = True)\n",
    "        dds = (col2.iloc[:,3]).str.split(pat=', ',expand = True)\n",
    "        acs = ((col2.iloc[:,1]).str.split(pat=' ',expand = True))\n",
    "\n",
    "        col2 = df.iloc[:,1]\n",
    "        col2 = col2.str.split (pat = '\\r',expand = True)\n",
    "        dds = (col2.iloc[:,3]).str.split(pat=', ',expand = True)\n",
    "        dds_header = dds.iloc[0]# Save first row for headers\n",
    "        dds = dds[1:]\n",
    "        dds.columns = dds_header\n",
    "        acs = ((col2.iloc[:,1]).str.split(pat=' ',expand = True))\n",
    "        acs_header = acs.iloc[0]# acs.iloc[0]# Save first row for headers\n",
    "        acs.columns = acs_header\n",
    "        acs=acs[1:]\n",
    "        # remove columns that have been expaned and concatenate dataframes\n",
    "        col2 = col2.drop(columns = [1,3])\n",
    "        col2_header = col2.iloc[0]# Save first row for headers\n",
    "        col2.columns = col2_header\n",
    "        col2 = col2[1:]\n",
    "         # expand column 3 in df the same way as 2 but assign header values\n",
    "        col3 = (df.iloc[:,2]).str.split(pat='\\r', expand = True)\n",
    "\n",
    "        col3_header = ['Owner1','Owner1_location','Owner2','Owner2_location', 'Rider']\n",
    "        col3.columns = col3_header\n",
    "        col3=col3[1:]\n",
    "        col3=col3['Rider']# We are only using this information for the analysis\n",
    "\n",
    "        #col4 = (df.iloc[:,3]).str.split(pat='\\r', expand = True)\n",
    "       # col4_header = col4.iloc[0]\n",
    "       # col4.columns = ['Breeder', 'overflow', 'BreederLoc1', 'BreederLoc1', 'overflow2'] #considering adding overflow to the original columns. IDK how that is going to work. \n",
    "       # col4=col4[1:]\n",
    "        #drop the columns that have been expanded & those not used\n",
    "        df2 = df.drop(columns = [1,2,3,4,5,6,7])\n",
    "        df2_header = df2.iloc[0] #promote the first row to headers \n",
    "        df2= df2[1:]\n",
    "        df2.columns = df2_header\n",
    "        df = pd.concat([col2,dds,acs,col3,df2], axis=1)#concatenate the expanded data\n",
    "        df['Sex'] = np.where(df.iloc[:,7].notnull(), df.iloc[:,7],df['Sex'])#some of the sex information got pushed into another column using the \" \" as a delimiter. This moves it back\n",
    "        #Some entrants did not list color and the sex information was stored in the color field\n",
    "       \n",
    "        df['Sex']=np.where(df['Color,'].isin(sex_list), df['Color,'], df['Sex'])\n",
    "        df = df.rename(columns = {'Color,':'Color'})\n",
    "        df = df.rename(columns = {'Age,':'Age'})\n",
    "\n",
    "    elif fvals[2] == '2018' :\n",
    "        col2 = df.iloc[:,1]\n",
    "        col2 = col2.str.split (pat = '\\r',expand = True)\n",
    "        horse_age_color_sex = col2.iloc[:,0].str.split(pat = '(', expand = True)\n",
    "        col2 = col2.drop(columns = [0])\n",
    "        age_color_sex = horse_age_color_sex.iloc[:,1].str.split(pat='‚Äê', expand = True)\n",
    "        age_color_sex = age_color_sex[1:]\n",
    "        horse = horse_age_color_sex.drop(columns = 1)\n",
    "        horse_head = ['Horse']\n",
    "        horse=horse[1:]\n",
    "        horse.columns = horse_head\n",
    "        acs_header = ['Age', 'Color', 'Sex']\n",
    "        age_color_sex = age_color_sex.drop(columns = 3)\n",
    "        age_color_sex.columns = acs_header\n",
    "        #replace any erroneous sex data that is be in the color column\n",
    "       # age_color_sex['Sex']=np.where(age_color_sex['Color'].isin(sex_list), age_color_sex['Color'], age_color_sex['Sex'])\n",
    "        sex_dict = {'G)':'Gelding','M)':'Mare','S)':'Stallion', ' M)':'Mare', 'Bay':'Gelding'} # replace abbreviation with word and brute force change one erroneous point of Bay\n",
    "        age_color_sex = age_color_sex.replace(to_replace = sex_dict)\n",
    "        col2_header = col2.iloc[0]# Save first row for headers\n",
    "        col2.columns = col2_header\n",
    "        col2 = col2[1:]\n",
    "       \n",
    "        col3 = (df.iloc[:,3]).str.split(pat='\\r', expand = True)\n",
    "        col3=col3.drop(columns = 1)\n",
    "        col3_header = ['Rider']\n",
    "        col3.columns = col3_header\n",
    "        col3=col3[1:]\n",
    "        df2 = df.drop(columns = [1,2,3,4,5,6,])\n",
    "        df2_header = df2.iloc[0] #promote the first row to headers \n",
    "        df2= df2[1:]\n",
    "        df2.columns = df2_header\n",
    "        df = pd.concat([horse,age_color_sex,col2,col3,df2], axis=1)#concatenate the expanded data\n",
    "    else:\n",
    "        col2 = df.iloc[:,1]# remove the second column to expand\n",
    "        col2 = col2.str.split(pat = '\\r',expand = True)\n",
    "        dds = col2[2].str.split(pat = ',',expand = True) # split dam and dams sire into separate columns\n",
    "        dds_header = dds.iloc[0]# Save first row for headers\n",
    "        dds=dds[1:]\n",
    "        dds.columns = dds_header\n",
    "        horse_age_color_sex = col2.iloc[:,0].str.split(pat = '(', expand = True)\n",
    "        col2 = col2.drop(columns = [0,2])\n",
    "        horse = horse_age_color_sex.drop(columns = 1)\n",
    "        horse_head = ['Horse']\n",
    "        horse=horse[1:]\n",
    "        horse.columns = horse_head\n",
    "        age_color_sex = horse_age_color_sex[1]#further break up column 2\n",
    "        age_color_sex = age_color_sex.str.split(pat='-', expand = True)\n",
    "        age_color_sex = age_color_sex[1:]\n",
    "        acs_header = ['Age', 'Color', 'Sex']\n",
    "        age_color_sex.columns = acs_header\n",
    "       \n",
    "        #replace any erroneous sex data that is be in the color column\n",
    "        age_color_sex['Sex']=np.where(age_color_sex['Color'].isin(sex_list), age_color_sex['Color'], age_color_sex['Sex'])\n",
    "      \n",
    "        age_color_sex = age_color_sex.replace(to_replace = sex_dict)\n",
    "        \n",
    "        col2_header = col2.iloc[0]\n",
    "        col2.columns = col2_header\n",
    "        col2 = col2[1:]\n",
    "        col3 = (df.iloc[:,2]).str.split(pat='\\r', expand = True) # Expand column 3\n",
    "        col3_header = ['Rider']\n",
    "       \n",
    "        # rider information was stored in the owner column in 2019 if the owner rode the horse, moving to the rider column\n",
    "        col3[2] = np.where(col3.iloc[:,2].str.contains(pat = ','), col3.iloc[:,0],col3[2]) #moves owner to rider column if address carried over\n",
    "        col3[2] = np.where(col3.iloc[:,2].isnull(), col3.iloc[:,0],col3[2]) #moves owner to rider column if there is no data in rider column\n",
    "        \n",
    "        col3 = col3.drop(columns = [0,1])\n",
    "        col3.columns = col3_header\n",
    "        col3=col3[1:]        \n",
    "        df2 = df.drop(columns = [1,2,3,4,5,6,])\n",
    "        df2_header = df2.iloc[0] #promote the first row to headers \n",
    "        df2= df2[1:]\n",
    "        df2.columns = df2_header\n",
    "        df = pd.concat([horse,age_color_sex,col2,col3,df2], axis=1)#concatenate the expanded data\n",
    "   \n",
    "    #remove header information carried over from converting each page of PDF files to CSV\n",
    "    df.drop(df.loc[df['Sire']=='Sire'].index, inplace=True)\n",
    "    # reset the index then rename index as the round results for that file\n",
    "    df.reset_index(inplace=True)\n",
    "       #rename index from \n",
    "    f = file\n",
    "    fvals = f.split(sep = '.')\n",
    "    fvals = fvals[0]\n",
    "    fvals=fvals.split(sep = '-')\n",
    "    indexstring = ' '.join(fvals[3:])\n",
    "    indexstring = indexstring + ' Place'\n",
    "    df = df.rename(columns = {'index':indexstring})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the files of interest and merge them. ###\n",
    "<p> Formatting and reporting styles of results each year varies and results in slightly different processing order and methods of merging the files.  Some repetition of code was necessary give </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        The Goodbye Lane\n",
       "1         Blazin Jetolena\n",
       "2        The Goodbye Lane\n",
       "3         Blazin Jetolena\n",
       "4        The Goodbye Lane\n",
       "             ...         \n",
       "72       Pc Redwood Manny\n",
       "73           Dash Ta Fame\n",
       "74       Dats A Frenchman\n",
       "75          Eddie Stinson\n",
       "76    Bhr Frenchies Socks\n",
       "Name: Sire, Length: 77, dtype: string"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The '#' did not represent a unique identifier for each horse in 2018, but the placing in any particular event or round.\n",
    "The  # was dropped and files are merged.  \n",
    "'''  \n",
    "go1_18 = expandcolumns_goround('PB-Futurity-2018-1st-Go.csv').drop(columns = ['#'])\n",
    "go2_18 = expandcolumns_goround('PB-Futurity-2018-2nd-Go.csv').drop(columns = ['#'])\n",
    "pbf_18 = pd.merge(go1_18,go2_18, how = \"outer\")\n",
    "\n",
    "#Eddie S nson is not a unique sire... Lets change that back to Eddie StinJson\n",
    "replace = {'Eddie S nson':'Eddie Stinson','BHR Frenchie Socks':'BHR Frenchies Socks'}\n",
    "pbf_18.replace(to_replace = replace, inplace = True)\n",
    "\n",
    "#format data types as needed\n",
    "pbf_18 = pbf_18.astype({'Horse' : 'string', 'Age':'float64', 'Color' : 'string', 'Sex' : 'string', 'Sire' : 'string', 'Dam' : 'string',\n",
    "       \"Dam's Sire\":'string', 'Rider' : 'string', '1st Go': 'float64', '2nd Go': 'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 2019 onward the # was a unique identifier which allowed me to merge with the unique identifier. \n",
    "\n",
    "\n",
    "go1_19 = expandcolumns_goround('PB-Futurity-2019-1st-Go.csv')\n",
    "go2_19 = expandcolumns_goround('PB-Futurity-2019-2nd-Go.csv').drop(columns = ['Horse', 'Age', 'Color', 'Sex', 'Sire', 'Rider'])\n",
    "pbf_19 = pd.merge(go1_19,go2_19, how =\"outer\") \n",
    "\n",
    "\n",
    "go1_20 = expandcolumns_goround('PB-Futurity-2020-1st-Go.csv')\n",
    "go2_20 = expandcolumns_goround('PB-Futurity-2020-2nd-Go.csv').drop(columns = ['Horse', 'Age', 'Color', 'Sex','Rider', 'Sire', 'Dam', \"Dam's Sire\"])\n",
    "pbf_20 = pd.merge(go1_20,go2_20, on ='#').drop(columns = ['None_x','None_y'])\n",
    "\n",
    "#change time, placing and year to integers\n",
    "pbf_19 = pbf_19.astype({'Horse' : 'string', 'Age':'int64', 'Color' : 'string', 'Sex' : 'string', 'Sire' : 'string',\n",
    "        'Rider' : 'string', '1st Go': 'float64', '2nd Go': 'float64'})\n",
    "pbf_20 = pbf_20.astype({'Horse' : 'string', 'Age':'float64', 'Color' : 'string', 'Sex' : 'string', 'Sire' : 'string', 'Dam' : 'string',\n",
    "       \"Dam's Sire\":'string', 'Rider' : 'string', '1st Go': 'float64', '2nd Go': 'float64'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each years results to a csv to be called as needed\n",
    "\n",
    "pbf_18.to_csv('./CSV_Analysis/2018_Futurity')\n",
    "pbf_19.to_csv('./CSV_Analysis/2019_Futurity')\n",
    "pbf_20.to_csv('./CSV_Analysis/2020_Futurity')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
