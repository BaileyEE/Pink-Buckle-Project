{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#Asses data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to expand the cells in our data frame concatenate the expanded files, then drop the information we won't be using in this analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#</td>\n",
       "      <td>Horse\\rAge, Color, Sex\\rSire\\rDam, Dam's Sire</td>\n",
       "      <td>Owner / Rider</td>\n",
       "      <td>Breeder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1st Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>VF Cream Rises\\r2016 Sorrel Mare\\rEddie Stinso...</td>\n",
       "      <td>Ademir Jose Rorato\\r\\rLexington, OK\\r\\rKelsey ...</td>\n",
       "      <td>Victory Farms\\r\\rA\\rda, OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>186</td>\n",
       "      <td>KN Snap Back\\r2016 Mare\\rEddie Stinson\\rKN Han...</td>\n",
       "      <td>Julien Veileux\\r\\rSt. Alfred, Quebec\\r\\rCaroli...</td>\n",
       "      <td>Stephen Nicholes\\r\\rBrownwood, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>163</td>\n",
       "      <td>The Right Version\\r2015 Gray Mare\\rWinners Ver...</td>\n",
       "      <td>Joe Hadley\\r\\rPlain City, UT\\r\\rMcKinlee Kellett</td>\n",
       "      <td>Joe Hadley\\r\\rP  l a  i n City, UT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>Makana\\r2015 Sorrel Mare\\rSlick By Design\\rRod...</td>\n",
       "      <td>Michele McLeod\\r\\rOntario, OR\\r\\rLindsey McLeod</td>\n",
       "      <td>C  h   a  r l i e    C  o  l e    &amp;    J a  s ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                                                  1  \\\n",
       "0    #      Horse\\rAge, Color, Sex\\rSire\\rDam, Dam's Sire   \n",
       "1   13  VF Cream Rises\\r2016 Sorrel Mare\\rEddie Stinso...   \n",
       "2  186  KN Snap Back\\r2016 Mare\\rEddie Stinson\\rKN Han...   \n",
       "3  163  The Right Version\\r2015 Gray Mare\\rWinners Ver...   \n",
       "4   18  Makana\\r2015 Sorrel Mare\\rSlick By Design\\rRod...   \n",
       "\n",
       "                                                   2  \\\n",
       "0                                      Owner / Rider   \n",
       "1  Ademir Jose Rorato\\r\\rLexington, OK\\r\\rKelsey ...   \n",
       "2  Julien Veileux\\r\\rSt. Alfred, Quebec\\r\\rCaroli...   \n",
       "3   Joe Hadley\\r\\rPlain City, UT\\r\\rMcKinlee Kellett   \n",
       "4    Michele McLeod\\r\\rOntario, OR\\r\\rLindsey McLeod   \n",
       "\n",
       "                                                   3    4    5    6    7  \\\n",
       "0                                            Breeder  NaN  NaN  NaN  NaN   \n",
       "1                         Victory Farms\\r\\rA\\rda, OK  NaN  NaN    O  NaN   \n",
       "2                  Stephen Nicholes\\r\\rBrownwood, TX  NaN  NaN    O  NaN   \n",
       "3                 Joe Hadley\\r\\rP  l a  i n City, UT  NaN  NaN    O  NaN   \n",
       "4  C  h   a  r l i e    C  o  l e    &    J a  s ...  NaN  NaN    O  NaN   \n",
       "\n",
       "        8  \n",
       "0  1st Go  \n",
       "1  17.067  \n",
       "2  17.070  \n",
       "3  17.102  \n",
       "4  17.125  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Asses raw data files and apply function above to begin cleaning the data\n",
    "#Year and Go-round could be inputs or pulled from the file string to be \n",
    "df = pd.read_csv(\"PB-Futurity-2020-1st-Go.csv\",  header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandcolumns_goround(file):\n",
    "    '''\n",
    "    INPUT string of path to CSV file converted from PDF of go round results from Pink Buckle Futurity\n",
    "    result formatting varies by year. \n",
    "    OUTPUT dataframe containing information relative to a stallion's offspring performance\n",
    "    '''\n",
    "    df = pd.read_csv(file,  header = None)\n",
    "    f = file\n",
    "    fvals = f.split(sep = '.')\n",
    "    fvals = fvals[0]\n",
    "    fvals=fvals.split(sep = '-')\n",
    "    sex_list = ['Gelding','Mare','Stallion','M','G','S']\n",
    "    sex_dict = {'G)':'Gelding','M)':'Mare','S)':'Stallion', ' M)':'Mare', 'G':'Gelding'}\n",
    "    if fvals[2] == '2020':\n",
    "    #break column 2 into its own data frame, then create tidy data by ensuring each type of \"observation\" has its own column\n",
    "        col2 = df.iloc[:,1]\n",
    "        col2 = col2.str.split (pat = '\\r',expand = True)\n",
    "        dds = (col2.iloc[:,3]).str.split(pat=', ',expand = True)\n",
    "        acs = ((col2.iloc[:,1]).str.split(pat=' ',expand = True))\n",
    "\n",
    "        col2 = df.iloc[:,1]\n",
    "        col2 = col2.str.split (pat = '\\r',expand = True)\n",
    "        dds = (col2.iloc[:,3]).str.split(pat=', ',expand = True)\n",
    "        dds_header = dds.iloc[0]# Save first row for headers\n",
    "        dds = dds[1:]\n",
    "        dds.columns = dds_header\n",
    "        acs = ((col2.iloc[:,1]).str.split(pat=' ',expand = True))\n",
    "        acs_header = acs.iloc[0]# acs.iloc[0]# Save first row for headers\n",
    "        acs.columns = acs_header\n",
    "        acs=acs[1:]\n",
    "        # remove columns that have been expaned and concatenate dataframes\n",
    "        col2 = col2.drop(columns = [1,3])\n",
    "        col2_header = col2.iloc[0]# Save first row for headers\n",
    "        col2.columns = col2_header\n",
    "        col2 = col2[1:]\n",
    "         # expand column 3 in df the same way as 2 but assign header values\n",
    "        col3 = (df.iloc[:,2]).str.split(pat='\\r', expand = True)\n",
    "\n",
    "        col3_header = ['Owner1','Owner1_location','Owner2','Owner2_location', 'Rider']\n",
    "        col3.columns = col3_header\n",
    "        col3=col3[1:]\n",
    "        col3=col3['Rider']# We are only using this information for the analysis\n",
    "\n",
    "        #col4 = (df.iloc[:,3]).str.split(pat='\\r', expand = True)\n",
    "       # col4_header = col4.iloc[0]\n",
    "       # col4.columns = ['Breeder', 'overflow', 'BreederLoc1', 'BreederLoc1', 'overflow2'] #considering adding overflow to the original columns. IDK how that is going to work. \n",
    "       # col4=col4[1:]\n",
    "        #drop the columns that have been expanded & those not used\n",
    "        df2 = df.drop(columns = [1,2,3,4,5,6,7])\n",
    "        df2_header = df2.iloc[0] #promote the first row to headers \n",
    "        df2= df2[1:]\n",
    "        df2.columns = df2_header\n",
    "        df = pd.concat([col2,dds,acs,col3,df2], axis=1)#concatenate the expanded data\n",
    "        df['Sex'] = np.where(df.iloc[:,7].notnull(), df.iloc[:,7],df['Sex'])#some of the sex information got pushed into another column using the \" \" as a delimiter. This moves it back\n",
    "        #Some entrants did not list color and the sex information was stored in the color field\n",
    "       \n",
    "        df['Sex']=np.where(df['Color,'].isin(sex_list), df['Color,'], df['Sex'])\n",
    "        df = df.rename(columns = {'Color,':'Color'})\n",
    "        df = df.rename(columns = {'Age,':'Age'})\n",
    "\n",
    "    elif fvals[2] == '2018' :\n",
    "        col2 = df.iloc[:,1]\n",
    "        col2 = col2.str.split (pat = '\\r',expand = True)\n",
    "        horse_age_color_sex = col2.iloc[:,0].str.split(pat = '(', expand = True)\n",
    "        col2 = col2.drop(columns = [0])\n",
    "        age_color_sex = horse_age_color_sex.iloc[:,1].str.split(pat='‚Äê', expand = True)\n",
    "        age_color_sex = age_color_sex[1:]\n",
    "        horse = horse_age_color_sex.drop(columns = 1)\n",
    "        horse_head = ['Horse']\n",
    "        horse=horse[1:]\n",
    "        horse.columns = horse_head\n",
    "        acs_header = ['Age', 'Color', 'Sex']\n",
    "        age_color_sex = age_color_sex.drop(columns = 3)\n",
    "        age_color_sex.columns = acs_header\n",
    "        #replace any erroneous sex data that is be in the color column\n",
    "       # age_color_sex['Sex']=np.where(age_color_sex['Color'].isin(sex_list), age_color_sex['Color'], age_color_sex['Sex'])\n",
    "        sex_dict = {'G)':'Gelding','M)':'Mare','S)':'Stallion', ' M)':'Mare', 'Bay':'Gelding'} # replace abbreviation with word and brute force change one erroneous point of Bay\n",
    "        age_color_sex = age_color_sex.replace(to_replace = sex_dict)\n",
    "        col2_header = col2.iloc[0]# Save first row for headers\n",
    "        col2.columns = col2_header\n",
    "        col2 = col2[1:]\n",
    "       \n",
    "        col3 = (df.iloc[:,3]).str.split(pat='\\r', expand = True)\n",
    "        col3=col3.drop(columns = 1)\n",
    "        col3_header = ['Rider']\n",
    "        col3.columns = col3_header\n",
    "        col3=col3[1:]\n",
    "        df2 = df.drop(columns = [1,2,3,4,5,6,])\n",
    "        df2_header = df2.iloc[0] #promote the first row to headers \n",
    "        df2= df2[1:]\n",
    "        df2.columns = df2_header\n",
    "        df = pd.concat([horse,age_color_sex,col2,col3,df2], axis=1)#concatenate the expanded data\n",
    "    else:\n",
    "        col2 = df.iloc[:,1]# remove the second column to expand\n",
    "        col2 = col2.str.split(pat = '\\r',expand = True)\n",
    "        dds = col2[2].str.split(pat = ',',expand = True) # split dam and dams sire into separate columns\n",
    "        dds_header = dds.iloc[0]# Save first row for headers\n",
    "        dds=dds[1:]\n",
    "        dds.columns = dds_header\n",
    "        horse_age_color_sex = col2.iloc[:,0].str.split(pat = '(', expand = True)\n",
    "        col2 = col2.drop(columns = [0,2])\n",
    "        horse = horse_age_color_sex.drop(columns = 1)\n",
    "        horse_head = ['Horse']\n",
    "        horse=horse[1:]\n",
    "        horse.columns = horse_head\n",
    "        age_color_sex = horse_age_color_sex[1]#further break up column 2\n",
    "        age_color_sex = age_color_sex.str.split(pat='-', expand = True)\n",
    "        age_color_sex = age_color_sex[1:]\n",
    "        acs_header = ['Age', 'Color', 'Sex']\n",
    "        age_color_sex.columns = acs_header\n",
    "        #replace any erroneous sex data that is be in the color column\n",
    "        age_color_sex['Sex']=np.where(age_color_sex['Color'].isin(sex_list), age_color_sex['Color'], age_color_sex['Sex'])\n",
    "      \n",
    "        age_color_sex = age_color_sex.replace(to_replace = sex_dict)\n",
    "        \n",
    "        col2_header = col2.iloc[0]\n",
    "        col2.columns = col2_header\n",
    "        col2 = col2[1:]\n",
    "        col3 = (df.iloc[:,2]).str.split(pat='\\r', expand = True) # Expand column 3\n",
    "        col3_header = ['Rider']\n",
    "        # rider information was stored in the owner column in 2019 if the owner rode the horse, moving to the rider column\n",
    "        col3[2] = np.where(col3.iloc[:,2].str.contains(pat = ','), col3.iloc[:,0],col3[2]) #moves owner to rider column if address carried over\n",
    "        col3[2] = np.where(col3.iloc[:,2].isnull(), col3.iloc[:,0],col3[2]) #moves owner to rider column if there is no data in rider column\n",
    "        \n",
    "        col3 = col3.drop(columns = [0,1])\n",
    "        col3.columns = col3_header\n",
    "        col3=col3[1:]        \n",
    "        df2 = df.drop(columns = [1,2,3,4,5,6,])\n",
    "        df2_header = df2.iloc[0] #promote the first row to headers \n",
    "        df2= df2[1:]\n",
    "        df2.columns = df2_header\n",
    "        df = pd.concat([horse,age_color_sex,col2,col3,df2], axis=1)#concatenate the expanded data\n",
    "   \n",
    "    #remove header information carried over from converting each pafe of PDF files to CSV\n",
    "    df.drop(df.loc[df['Sire']=='Sire'].index, inplace=True)\n",
    "    # reset the index then rename index as the round results for that file\n",
    "    df.reset_index(inplace=True)\n",
    "       #rename index from \n",
    "    f = file\n",
    "    fvals = f.split(sep = '.')\n",
    "    fvals = fvals[0]\n",
    "    fvals=fvals.split(sep = '-')\n",
    "    indexstring = ' '.join(fvals[2:])\n",
    "    df = df.rename(columns = {'index':indexstring})\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the files of interest and merge them.  Formatting and reporting styles of results each year varies and results in slightly different processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "go1_18 = expandcolumns_goround('PB-Futurity-2018-1st-Go.csv').drop(columns = ['#'])\n",
    "go2_18 = expandcolumns_goround('PB-Futurity-2018-2nd-Go.csv').drop(columns = ['#'])\n",
    "pbf_18 = pd.merge(go1_18,go2_18, how = \"outer\")\n",
    "\n",
    "#Amateur cells are commented out but left in place for future analysis\n",
    "#am = pd.merge(go1_18_am,go2_18_am)\n",
    "#pbf_18=pd.merge(pbf_18, am,how= \"outer\")\n",
    "\n",
    "#Eddie S nson is not a unique sire... Lets change that back to Eddie StinJson\n",
    "replace = {'Eddie S nson':'Eddie Stinson'}\n",
    "pbf_18.replace(to_replace = replace, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018 1st Go    float64\n",
       "Horse           string\n",
       "Age            float64\n",
       "Color           string\n",
       "Sex             string\n",
       "Sire            string\n",
       "Dam             string\n",
       "Dam's Sire      string\n",
       "Rider           string\n",
       "1st Go         float64\n",
       "2018 2nd Go    float64\n",
       "2nd Go         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change time, placing and year to integers\n",
    "pbf_18 = pbf_18.astype({'Horse' : 'string', 'Age':'float64', 'Color' : 'string', 'Sex' : 'string', 'Sire' : 'string', 'Dam' : 'string',\n",
    "       \"Dam's Sire\":'string', 'Rider' : 'string', '1st Go': 'float64', '2nd Go': 'float64'})\n",
    "\n",
    "pbf_18.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expandcolumns_goround' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4d4ef47ca89c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgo1_19\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpandcolumns_goround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PB-Futurity-2019-1st-Go.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgo2_19\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpandcolumns_goround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PB-Futurity-2019-2nd-Go.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Horse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Age'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Color'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sire'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Rider'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#go1_19_am = expandcolumns_goround('PB-Futurity-2019-1st-Go-Am.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#go2_19_am = expandcolumns_goround('PB-Futurity-2019-2nd-Go-Am.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'expandcolumns_goround' is not defined"
     ]
    }
   ],
   "source": [
    "go1_19 = expandcolumns_goround('PB-Futurity-2019-1st-Go.csv')\n",
    "go2_19 = expandcolumns_goround('PB-Futurity-2019-2nd-Go.csv').drop(columns = ['Horse', 'Age', 'Color', 'Sex', 'Sire', 'Rider'])\n",
    "#go1_19_am = expandcolumns_goround('PB-Futurity-2019-1st-Go-Am.csv')\n",
    "#go2_19_am = expandcolumns_goround('PB-Futurity-2019-2nd-Go-Am.csv')\n",
    "\n",
    "\n",
    "#pbf_19 = go1_19.set_index('#').join(go2_19.set_index('#')) #join first and 2nd go into one table\n",
    "\n",
    "pbf_19 = pd.merge(go1_19,go2_19, how =\"outer\")\n",
    "#am = pd.merge(go1_19_am,go2_19_am)\n",
    "#pbf_19=pd.merge(pbf_19, am,how=\"outer\")\n",
    "pbf_19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go1_20 = expandcolumns_goround('PB-Futurity-2020-1st-Go.csv')\n",
    "go2_20 = expandcolumns_goround('PB-Futurity-2020-2nd-Go.csv').drop(columns = ['Horse', 'Age', 'Color', 'Sex','Rider', 'Sire', 'Dam', \"Dam's Sire\"])\n",
    "#go2_20_am = expandcolumns_goround('PB-Futurity-2020-2nd-Go-Am-1.csv')\n",
    "#go1_20_am = expandcolumns_goround('PB-Futurity-2020-1st-Go-Am.csv')\n",
    "#pbf_20 = go1_20.set_index('#').join(go2_20.set_index('#'))\n",
    "pbf_20 = pd.merge(go1_20,go2_20, on ='#').drop(columns = ['None_x','None_y'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
